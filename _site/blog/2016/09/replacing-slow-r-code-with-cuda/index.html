<!DOCTYPE html>

<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
    <meta charset="utf-8">
<!--[if IE]><meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'><![endif]-->
<meta name="viewport" content="width=device-width,initial-scale=1">

<!-- Begin Jekyll SEO tag v2.3.0 -->
<title>Replacing Slow R Code with CUDA | John Ensley</title>
<meta property="og:title" content="Replacing Slow R Code with CUDA" />
<meta name="author" content="John Ensley" />
<meta property="og:locale" content="en" />
<link rel="canonical" href="http://localhost:4000/blog/2016/09/replacing-slow-r-code-with-cuda/" />
<meta property="og:url" content="http://localhost:4000/blog/2016/09/replacing-slow-r-code-with-cuda/" />
<meta property="og:site_name" content="John Ensley" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2016-09-16T00:00:00-04:00" />
<script type="application/ld+json">
{"name":null,"description":null,"author":{"@type":"Person","name":"John Ensley"},"@type":"BlogPosting","url":"http://localhost:4000/blog/2016/09/replacing-slow-r-code-with-cuda/","publisher":null,"image":null,"headline":"Replacing Slow R Code with CUDA","dateModified":"2016-09-16T00:00:00-04:00","datePublished":"2016-09-16T00:00:00-04:00","sameAs":null,"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2016/09/replacing-slow-r-code-with-cuda/"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<meta name="keywords" content="R,C,GPU,CUDA" />





<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="John Ensley" />
    <link href='/assets/stylesheets/blog.css' rel="stylesheet" type="text/css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.min.js"></script>
<script>window.Modernizr || document.write('<script src="/assets/javascripts/modernizr-2.8.3.min.js"><\/script>')</script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
<script>
    window.jQuery || document.write('<script src="/assets/javascripts/jquery-3.2.1.min.js"><\/script>')
</script>

<!-- <script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script>
<script>
    window.Pace || document.write('<script src="/assets/javascripts/pace.min.js"><\/script>')
</script> -->

<script>
  (function(d) {
    var config = {
      kitId: "apq8pzh",
      scriptTimeout: 3000,
      async: true
    },
    h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)
  })(document);
</script>


    <script async src="https://www.google-analytics.com/analytics.js"></script>
<script async src="/assets/javascripts/autotrack.js"></script>
<script>

window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-46465113-2', 'auto');

ga('require', 'cleanUrlTracker', {
  trailingSlash: 'remove'
});
ga('require', 'maxScrollTracker');
ga('require', 'mediaQueryTracker', {
  definitions: [
    {
      name: 'Breakpoint',
      dimensionIndex: 1,
      items: [
        {name: 'sm', media: 'all'},
        {name: 'md', media: '(min-width: 768px)'},
        {name: 'lg', media: '(min-width: 1200px)'}
      ]
    },
    {
      name: 'Pixel Density',
      dimensionIndex: 2,
      items: [
        {name: '1x',   media: 'all'},
        {name: '1.5x', media: '(min-resolution: 144dpi)'},
        {name: '2x',   media: '(min-resolution: 192dpi)'}
      ]
    },
    {
      name: 'Orientation',
      dimensionIndex: 3,
      items: [
        {name: 'landscape', media: '(orientation: landscape)'},
        {name: 'portrait',  media: '(orientation: portrait)'}
      ]
    }
  ]
});
ga('require', 'outboundLinkTracker', {
  events: ['click', 'auxclick', 'contextmenu']
});
ga('require', 'pageVisibilityTracker', {
  sendInitialPageview: true,
});

ga('send', 'pageview');

function sendGaEvent(category, action, element, value) {
    var title = element.getAttribute('title');
    var textConent = element.textContent ? element.textContent.trim() : undefined;
    var label = (title && title.length !== 0) ? title : textConent;
    ga('send', {
        hitType: 'event',
        eventCategory: category,
        eventAction: action.trim(),
        eventLabel: label,
        eventValue: value
    });
}
</script>

</head>

<body>

    <div id="page" class="hentry">
        <header class="the-header">
    <div class="unit-head">
        <div class="unit-inner unit-head-inner">
            <nav class="nav-global">
                <ul>
                    <li class="logo nav-link">
                        <button class="btn-menu" title="Menu"></button>
                        <a href="/">John Ensley</a>
                    </li>
                    <li class="nav-link"><a title="Blog" href="/blog/">Blog</a></li>
                    <li class="nav-link"><a title="Projects" href="/projects/">Projects</a></li>
                    <li class="nav-link"><a title="Photography" href="/photography/">Photography</a></li>
                    <li class="nav-link"><a title="About" href="/about/">About</a></li>
                </ul>
            </nav>
        </div>
    </div>
</header>


        <div class="body animated fadeInDown" role="main">
            <div class="unit-body">
                <div class="unit-inner unit-body-inner">
                    <div class="entry-content">
                        <article class="unit-article layout-post">
    <div class="unit-inner unit-article-inner">
        <div itemscope itemtype="http://schema.org/Article" class="content">
            <header>
                <div class="unit-head">
                    <div class="unit-inner unit-head-inner">
                        <h1 class="entry-title" itemprop="name">Replacing Slow R Code with CUDA</h1>
                    </div>
                </div>
            </header>
            <div class="bd article-content">
                <div class="entry-content">
                    <div class="meta">
                        <p class="date-publish">
                            Published:
                            <time itemprop="datePublished" class="date-pub updated"
                                title="2016-09-16T00:00:00-04:00" datetime="2016-09-16T00:00:00-04:00">September 16, 2016 </time>
                            by
                            <a class="author" href="/" rel="author" title="Show Author">
                                <span itemprop="author" itemscope itemtype="http://schema.org/Person">
                                    <span itemprop="name">John Ensley</span>
                                </span>
                            </a>
                            
                            
                        </p>
                        <ul class="list-category list-linear">
                            <li class="list-head"><a title="Categories" href="/blog/categories/">Categories</a>: </li>
                             
     
        <li>
            <a href="/blog/categories/#Research" title="Research">
            Research <span>3</span></a>
        </li>
    



                        </ul>
                        <ul class="list-tag list-linear">
                            <li class="list-head"><a title="Tags" href="/blog/tags/">Tags</a>: </li>
                             
    
        
        <li>
            <a href="/blog/tags/#C" title="C">C <span>3</span></a>
        </li>
    
        
        <li>
            <a href="/blog/tags/#CUDA" title="CUDA">CUDA <span>1</span></a>
        </li>
    
        
        <li>
            <a href="/blog/tags/#GPU" title="GPU">GPU <span>3</span></a>
        </li>
    
        
        <li>
            <a href="/blog/tags/#R" title="R">R <span>3</span></a>
        </li>
    




                        </ul>
                    </div>
                    <div itemprop="articleBody" class="article-body">
                        <ul class="toc" id="markdown-toc">
  <li><a href="#heading-the-problem" id="markdown-toc-heading-the-problem">The Problem</a></li>
  <li><a href="#heading-naive-r-solution" id="markdown-toc-heading-naive-r-solution">Naive R Solution</a></li>
  <li><a href="#heading-a-faster-r-solution" id="markdown-toc-heading-a-faster-r-solution">A Faster R Solution</a></li>
  <li><a href="#heading-parallelization-with-cuda" id="markdown-toc-heading-parallelization-with-cuda">Parallelization with CUDA</a></li>
  <li><a href="#heading-using-cuda-in-r" id="markdown-toc-heading-using-cuda-in-r">Using CUDA in R</a></li>
</ul>

<h1 id="heading-the-problem">The Problem</h1>

<p>Suppose we have a vector <script type="math/tex">\{x_i: i = 1, \dots, N\}</script> and a collection of <script type="math/tex">\{s_j: j = 1, \dots, M\}</script> random samples. For each <script type="math/tex">x_j</script>, we want to calculate</p>

<script type="math/tex; mode=display">\frac{1}{M} \sum_{j=1}^M \cos(x_is_j).</script>

<h1 id="heading-naive-r-solution">Naive R Solution</h1>

<p>If you were new to R, you might do something like this:</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">func1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w">
</span><span class="p">{</span><span class="w">
  </span><span class="n">N</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">
  </span><span class="n">M</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="w">
  </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w">
   
  </span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">M</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">cos</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">s</span><span class="p">[</span><span class="n">j</span><span class="p">])</span><span class="w">
    </span><span class="p">}</span><span class="w">
    </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">M</span><span class="w">
  </span><span class="p">}</span><span class="w">

  </span><span class="nf">return</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="w">
</span><span class="p">}</span></code></pre></figure>

<p>If you’ve had any experience with R, you probably recoiled in horror at the sight of those nested for loops. For loops are notoriously slow in R, and the function above is doing <script type="math/tex">N \times M</script> iterations with them. In fact, that’s probably the single worst way I could have written that function. If <script type="math/tex">N</script> and <script type="math/tex">M</script> are small then it doesn’t matter much, but even if <script type="math/tex">N=M=1000</script> (not big at all for practical applications), look what happens to the runtime:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Unit: seconds
        expr      min       lq     mean  median      uq      max neval
 func1(x, s) 1.608869 1.650864 1.718337 1.67365 1.77996 2.070576   100
</code></pre>
</div>

<p>It takes about 1.7 seconds on average to run. This is not ideal, especially in my research, where I need <script type="math/tex">N=80000</script> and <script type="math/tex">M=10000</script> at least, and then I need it to run tens of thousands of times.</p>

<h1 id="heading-a-faster-r-solution">A Faster R Solution</h1>

<p>Let’s try a different approach. R has <em>vectorized</em> functions, like <code class="highlighter-rouge">mean(x)</code>, which are much, much faster than doing the equivalent calculation with a loop.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">func2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Vectorize</span><span class="p">(</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">mean</span><span class="p">(</span><span class="nf">cos</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">s</span><span class="p">))</span><span class="w">
</span><span class="p">},</span><span class="w"> </span><span class="n">vectorize.args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'x'</span><span class="p">)</span></code></pre></figure>

<p>The calculation is taken care of in one line, <code class="highlighter-rouge">mean(cos(x*s))</code>. The function is wrapped in <code class="highlighter-rouge">Vectorize</code>, which tells R to apply the function to every element of <code class="highlighter-rouge">x</code>, one at a time. If we run this one with <script type="math/tex">N=M=1000</script>, we get</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Unit: milliseconds
        expr      min       lq     mean   median       uq      max neval
 func2(x, s) 27.50761 29.18643 31.93724 31.30861 33.46475 50.32115   100
</code></pre>
</div>

<p>That’s more like it. This runs in about 30 milliseconds, 50 times faster than the first function. Let’s bump up the sizes to <script type="math/tex">N=M=10000</script> and see what happens.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Unit: seconds
        expr      min       lq     mean   median       uq      max neval
 func2(x, s) 1.956879 2.039474 2.186676 2.151696 2.296424 3.011084   100
</code></pre>
</div>

<p>Hmm. The evaluation time has climbed up to more than 2 seconds. It doesn’t sound like much, but it really adds up when you’re calling this function thousands of times.</p>

<h1 id="heading-parallelization-with-cuda">Parallelization with CUDA</h1>

<p>We could rewrite the function in C, a lower-level language than R, but this only speeds things up by a factor of 2 or 3 at best. The main reason why this is so slow is that R (and ordinary C as well) is <em>single-threaded</em>. This means that R can only do one thing at a time. It takes <script type="math/tex">x_1</script>, calculates <script type="math/tex">\frac{1}{M}\sum^M_{j=1}\cos(x_1s_j)</script>, then takes <script type="math/tex">x_2</script>, calculates <script type="math/tex">\frac{1}{M}\sum^M_{j=1}\cos(x_2s_j)</script>, and so on until it hits <script type="math/tex">x_N</script>. But there’s no reason that things <em>must</em> be evaluated so sequentially. It would save a lot of time if we could do that calculation for lots of different <script type="math/tex">x_i</script>’s simultaneously. This is called <em>parallelization</em>.</p>

<p>CUDA is an API developed by Nvidia for doing parallel computing on a GPU (graphics processing unit). GPUs are designed with parallel computing in mind. They are essentially made up of thousands of little processors that are organized in such a way that they can split up a task, execute part of it, and recombine the results. Here is a CUDA file that accomplishes our task. I named it <code class="highlighter-rouge">mc.cu</code>.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;
</span>
<span class="cp">#include "mc.h"
</span>
<span class="cp">#define TPB 1024
</span>
<span class="n">__device__</span> <span class="kt">double</span> <span class="nf">mcCalc</span><span class="p">(</span><span class="kt">double</span> <span class="n">x</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">d_samps</span><span class="p">,</span> <span class="kt">int</span> <span class="n">S</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">double</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">S</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">cos</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">d_samps</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">total</span> <span class="o">/</span> <span class="n">S</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">mcKernel</span><span class="p">(</span><span class="kt">double</span> <span class="o">*</span><span class="n">d_vec</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">d_samps</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">d_mat</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="n">S</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">const</span> <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&gt;=</span> <span class="n">N</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
    <span class="k">const</span> <span class="kt">double</span> <span class="n">x</span> <span class="o">=</span> <span class="n">d_vec</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">d_mat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mcCalc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d_samps</span><span class="p">,</span> <span class="n">S</span><span class="p">);</span>
<span class="p">}</span>


<span class="c1">// Helper function for using CUDA to add vectors in parallel.
</span><span class="k">extern</span> <span class="s">"C"</span> <span class="kt">void</span> <span class="n">mcCuda</span><span class="p">(</span><span class="kt">double</span> <span class="o">*</span><span class="n">vec</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">samps</span><span class="p">,</span> <span class="kt">double</span> <span class="o">*</span><span class="n">mat</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">S</span><span class="p">)</span>
<span class="p">{</span>

    <span class="kt">double</span> <span class="o">*</span><span class="n">d_vec</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="kt">double</span> <span class="o">*</span><span class="n">d_samps</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="kt">double</span> <span class="o">*</span><span class="n">d_mat</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">cudaError_t</span> <span class="n">cudaStatus</span><span class="p">;</span>

    <span class="c1">// Choose which GPU to run on, change this on a multi-GPU system.
</span>    <span class="n">cudaStatus</span> <span class="o">=</span> <span class="n">cudaSetDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaStatus</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"cudaSetDevice failed!  Do you have a CUDA-capable GPU installed?"</span><span class="p">);</span>
        <span class="k">goto</span> <span class="n">Error</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Allocate GPU buffers for three vectors (two input, one output).
</span>    <span class="n">cudaStatus</span> <span class="o">=</span> <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_vec</span><span class="p">,</span> <span class="o">*</span><span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaStatus</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"cudaMalloc failed!"</span><span class="p">);</span>
        <span class="k">goto</span> <span class="n">Error</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">cudaStatus</span> <span class="o">=</span> <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_samps</span><span class="p">,</span> <span class="o">*</span><span class="n">S</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaStatus</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"cudaMalloc failed!"</span><span class="p">);</span>
        <span class="k">goto</span> <span class="n">Error</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">cudaStatus</span> <span class="o">=</span> <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_mat</span><span class="p">,</span> <span class="o">*</span><span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">));</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaStatus</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"cudaMalloc failed!"</span><span class="p">);</span>
        <span class="k">goto</span> <span class="n">Error</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Copy input vectors from host memory to GPU buffers.
</span>    <span class="n">cudaStatus</span> <span class="o">=</span> <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_vec</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="o">*</span><span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">),</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaStatus</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"cudaMemcpy failed!"</span><span class="p">);</span>
        <span class="k">goto</span> <span class="n">Error</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">cudaStatus</span> <span class="o">=</span> <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_samps</span><span class="p">,</span> <span class="n">samps</span><span class="p">,</span> <span class="o">*</span><span class="n">S</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">),</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaStatus</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"cudaMemcpy failed!"</span><span class="p">);</span>
        <span class="k">goto</span> <span class="n">Error</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Launch a kernel on the GPU with TPB threads per block.
</span>    <span class="n">mcKernel</span><span class="o">&lt;&lt;&lt;</span><span class="p">(</span><span class="o">*</span><span class="n">N</span><span class="o">+</span><span class="n">TPB</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">TPB</span><span class="p">,</span> <span class="n">TPB</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_vec</span><span class="p">,</span> <span class="n">d_samps</span><span class="p">,</span> <span class="n">d_mat</span><span class="p">,</span> <span class="o">*</span><span class="n">N</span><span class="p">,</span> <span class="o">*</span><span class="n">S</span><span class="p">);</span>

    <span class="c1">// Check for any errors launching the kernel
</span>    <span class="n">cudaStatus</span> <span class="o">=</span> <span class="n">cudaGetLastError</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaStatus</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"mcKernel launch failed: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">cudaStatus</span><span class="p">));</span>
        <span class="k">goto</span> <span class="n">Error</span><span class="p">;</span>
    <span class="p">}</span>
    
    <span class="c1">// cudaDeviceSynchronize waits for the kernel to finish, and returns
</span>    <span class="c1">// any errors encountered during the launch.
</span>    <span class="n">cudaStatus</span> <span class="o">=</span> <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaStatus</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"cudaDeviceSynchronize returned error code %d after launching mcKernel!</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">cudaStatus</span><span class="p">);</span>
        <span class="k">goto</span> <span class="n">Error</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Copy output vector from GPU buffer to host memory.
</span>    <span class="n">cudaStatus</span> <span class="o">=</span> <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">d_mat</span><span class="p">,</span> <span class="o">*</span><span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaStatus</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"cudaMemcpy failed!"</span><span class="p">);</span>
        <span class="k">goto</span> <span class="n">Error</span><span class="p">;</span>
    <span class="p">}</span>

<span class="n">Error</span><span class="o">:</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_vec</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_samps</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_mat</span><span class="p">);</span>

    <span class="n">cudaThreadExit</span><span class="p">();</span>
    
<span class="p">}</span></code></pre></figure>

<h1 id="heading-using-cuda-in-r">Using CUDA in R</h1>

<p>To use this in R, we need to compile it as a shared library object. I do this in two steps, although I'm not sure if it's strictly necessary. First I compile the source code (the <code class="highlighter-rouge">mc.cu</code> file above) into an object file called <code class="highlighter-rouge">mc.o</code>.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">nvcc -g -G -Xcompiler <span class="s2">"-Wall -Wextra -fpic"</span> -c src/mc.cu -o bin/mc.o</code></pre></figure>

<p>Then, in order for R to use it, I turn it into a shared library file called <code class="highlighter-rouge">mc.so</code>.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">nvcc -shared bin/mc.o -o mc.so -lm -lcuda -lcudart</code></pre></figure>

<p>I used a <em>makefile</em> so I wouldn't have to remember what to do every time. The makefile looks like this:</p>

<figure class="highlight"><pre><code class="language-make" data-lang="make"><span class="nl">all</span><span class="o">:</span> <span class="nf">bin/mc.so</span>

<span class="nl">bin/mc.so</span><span class="o">:</span> <span class="nf">bin/mc.o</span>
    <span class="err">nvcc</span> <span class="err">-shared</span> <span class="err">bin/mc.o</span> <span class="err">-o</span> <span class="err">mc.so</span> <span class="err">-lm</span> <span class="err">-lcuda</span> <span class="err">-lcudart</span>

<span class="nl">bin/mc.o</span><span class="o">:</span> <span class="nf">src/mc.cu src/mc.h</span>
    <span class="err">nvcc</span> <span class="err">-g</span> <span class="err">-G</span> <span class="err">-Xcompiler</span> <span class="s2">"-Wall -Wextra -fpic"</span> <span class="err">-c</span> <span class="err">src/mc.cu</span> <span class="err">-o</span> <span class="err">bin/mc.o</span>

<span class="nl">clean</span><span class="o">:</span>
    <span class="err">rm</span> <span class="err">bin/*.o</span></code></pre></figure>

<p>At this point, here is the structure of my directory.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>.
├── bin
│   └── mc.o
├── makefile
├── mc.so
└── src
    ├── mc.cu
    └── mc.h
</code></pre>
</div>

<p>Now, in an R session, first we need to load that compiled library with <code class="highlighter-rouge">dyn.load()</code>, and then we can write a wrapper function around the call to C.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">dyn.load</span><span class="p">(</span><span class="s1">'mc.so'</span><span class="p">)</span><span class="w">

</span><span class="n">covar_mc_cuda</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">samps</span><span class="p">)</span><span class="w">
</span><span class="p">{</span><span class="w">
  </span><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">
  </span><span class="n">s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">samps</span><span class="p">)</span><span class="w">
  </span><span class="n">tmp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">.C</span><span class="p">(</span><span class="s1">'mcCuda'</span><span class="p">,</span><span class="w"> </span><span class="nf">as.double</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="w"> </span><span class="nf">as.double</span><span class="p">(</span><span class="n">samps</span><span class="p">),</span><span class="w"> </span><span class="n">res</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">double</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w">
  </span><span class="n">tmp</span><span class="o">$</span><span class="n">res</span><span class="w">
</span><span class="p">}</span></code></pre></figure>

<p>Finally, we can use this function just like any other regular R function. When I tried this with <script type="math/tex">N=80200</script> and <script type="math/tex">M=10000</script>, it ran in about half a second. Pretty amazing if you ask me.</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">runif</span><span class="p">(</span><span class="m">80200</span><span class="p">)</span><span class="w">
</span><span class="n">s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="m">10000</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">)</span><span class="w">
</span><span class="n">system.time</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">covar_mc_cuda</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">s</span><span class="p">))</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>   user  system elapsed 
  0.284   0.176   0.463
</code></pre>
</div>

<p><strong>NOTE:</strong> If you don’t have an Nvidia GPU in your computer, this will not work for you. I don’t have one in mine, so I needed to use <a href="https://ics.psu.edu/advanced-cyberinfrastructure/">Penn State’s ICS-ACI computing cluster</a>, which was an adventure in itself. I have written <a href="/post/2016-09-13-running-cuda-scripts-on-penn-state-s-ics-aci-cluster/">another blog post</a> about how to do that.</p>

                    </div>
                </div>
            </div>
            <footer class="unit-foot">
                <div class="unit-inner unit-foot-inner">
                    <div class="post-buttons">
                        <a class="internal gotop" href="#page" title="Back to Top">Back to Top</a>
                        
                            <div class="addthis_toolbox addthis_default_style addthis_32x32_style">
    <small class="label">Share Post:</small>
    <a class="btn-share-post addthis_button_email"></a>
    <a class="btn-share-post addthis_button_facebook"></a>
    <a class="btn-share-post addthis_button_google_plusone_share"></a>
    <a class="btn-share-post addthis_button_reddit"></a>
    <a class="btn-share-post addthis_button_twitter"></a>
</div>
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-59d6642f0906b28f"></script>
                        
                    </div>
                    <nav class="pagination">
                        
                            <a class="internal" rel="prev" href="/blog/2016/09/running-cuda-scripts-on-penn-state-aci-cluster/" title=" 'Running CUDA Scripts on Penn State's ICS-ACI Cluster'"> ← Running CUDA Scripts on Penn State's ICS-ACI Cluster</a>
                        
                        
                            <a class="internal" rel="next" href="/blog/2017/02/how-your-favorite-baseball-team-blows-its-money-revisiting-a-fivethirtyeight-analysis/" title="Next Post '"How Your Favorite Baseball Team Blows Its Money": Revisiting a FiveThirtyEight Analysis'">"How Your Favorite Baseball Team Blows Its Money": Revisiting a FiveThirtyEight Analysis → </a>
                        
                    </nav>
                </div>
            </footer>
            <div class="misc-content">
                
                    <script>
    $(document).ready(function () {
        var disqusPublicKey = "P0se57dcTUHLZ5wLHfxm3x11coj3QQCwTchefL9CbWCE1PuUxZ8hTwv7Zpy9sRcI";
        var disqusShortname = "ensley";
        var threadUrl = 'link:' + $('.comments .show-hidden').attr('data-disqus-url');

        $.ajax({
            type: 'GET',
            url: '//disqus.com/api/3.0/threads/set.jsonp',
            data: {
                api_key: disqusPublicKey,
                forum: disqusShortname,
                thread: threadUrl
            },
            cache: false,
            dataType: 'jsonp',
            success: function (result) {
                if (result.response.length === 1) {
                    btnText = 'Show Comments (' + result.response[0].posts + ')';
                    $('.comments .show-hidden').html(btnText);
                }
            }
        });

        $('.comments .show-hidden').on('click', function () {
            $.ajaxSetup({cache: true});
            $.getScript('//' + disqusShortname + '.disqus.com/embed.js');
            $.ajaxSetup({cache: false});
            $(this).remove();
        });

        if (/\#comments/.test(location.hash)) {
            $('.comments .show-hidden').trigger('click');
        }
    });
</script>

                    <div class="comments">
                        <button class="center-block show-hidden" title="Show Comments" data-disqus-url="http://localhost:4000/blog/2016/09/replacing-slow-r-code-with-cuda/">Show Comments</button>
                        <div id="disqus_thread"></div>
                    </div>
                
            </div>
        </div>
    </div>
</article>

                    </div>
                </div>
            </div>
        </div>
        <footer class="the-footer">
    <div class="unit-foot">
        <div class="unit-inner unit-foot-inner">
            <div class="misc vcard">
                <div class="about">
                    <!-- <h4><a href="/">About</a></h4> -->
                    
                    <small>This site is powered by <a href="http://jekyllrb.com/">Jekyll</a>, <a href="https://kramdown.gettalong.org/">kramdown</a>, and <a href="https://pages.github.com/">GitHub Pages</a>.<br/>Based on the <a href="https://github.com/yizeng/jekyll-theme-simple-texture" target="_blank">Simple Texture</a> theme developed by <a href="http://yizeng.me" target="_blank">Yi Zeng</a>.</small>
                </div>
                <div class="social-links">
                    
                    <a class="ico-rss" href="/feed.xml" rel="me" target="_blank" title="feed"></a>
                    
                        
                            <a class="ico-github" href="https://github.com/ensley/" rel="me" target="_blank" title="github"></a>
                        
                    
                        
                            <a class="ico-instagram" href="https://instagram.com/john.ensley/" rel="me" target="_blank" title="instagram"></a>
                        
                    
                        
                            <a class="ico-linkedin" href="https://linkedin.com/in/john-ensley-61455986/" rel="me" target="_blank" title="linkedin"></a>
                        
                    
                        
                            <a class="ico-twitter" href="https://twitter.com/john__ensley/" rel="me" target="_blank" title="twitter"></a>
                        
                    
                </div>
            </div>
        </div>
    </div>
    <a href="#" class="internal back-to-top">Back to Top</a>
</footer>

    </div>

    <script>
$(document).ready(function () {
    var offset = 50,
        duration = 500,
        width = 960;
    $(window).scroll(function () {
        if ($(window).width() > width) {
            if ($(this).scrollTop() > offset) {
                $('footer').css('top', '20px');
                $('footer .back-to-top').fadeIn(duration);
            } else {
                $('footer').css('top', 'auto');
                $('footer .back-to-top').fadeOut(duration);
            }
        }
    });
    $(window).resize(function () {
        if ($(window).width() < width) {
            $('footer').css('top', 'auto');
            $('footer .back-to-top').fadeOut(duration);
        }
        if ($(window).width() >= width && $(this).scrollTop() > offset) {
            $('footer').css('top', '20px');
            $('footer .back-to-top').fadeIn(duration);
        }
    });

    $('footer .back-to-top, .gotop').on('click', function (event) {
        event.preventDefault();
        $('html, body').animate({
            scrollTop: 0
        }, duration);
        return false;
    });

    $('.show-hidden').on('click', function () {
        $(this).parent().next().toggleClass("hidden");
        $(this).toggleClass("hidden");
    });
});
</script>

<!-- Google Analytics Event tracking -->

<script>
$(document).on('click', 'footer .back-to-top, .gotop', function (event) {
    sendGaEvent('Blog', 'Back to Top', event.currentTarget);
});
$(document).on('click', '.show-hidden', function (event) {
    sendGaEvent('Post', 'Show Hidden', event.currentTarget);
});
$(document).on('click', 'a.internal', function(event) {
    sendGaEvent('Blog', 'Navigate', event.currentTarget);
});
$('.the-header').on('click', '.nav-link a, [class$=wrapper] .results a, .nav-link button', function(event) {
    sendGaEvent('Blog', 'Navigate', event.currentTarget);
});
$('.the-header').on('click', '.nav-link button', function(event) {
    sendGaEvent('Blog', 'Navigate', event.currentTarget);
});
$('.the-footer').on('click', '.about h4 a', function(event) {
    sendGaEvent('Blog', 'Go to About', event.currentTarget);
});
$('.the-footer').on('click', '.social-links a', function(event) {
    sendGaEvent('Blog', 'Click Social Link', event.currentTarget);
});
$('.unit-article').on('click', '.tag_box.categories a', function(event) {
    sendGaEvent('Blog', 'Click Category', event.currentTarget);
});
$('.unit-article').on('click', '.tag_box.tags a', function(event) {
    sendGaEvent('Blog', 'Click Tag', event.currentTarget);
});
$('.unit-article').on('click', '.comments .show-hidden', function(event) {
    sendGaEvent('Post', 'Show Comments', event.currentTarget);
});
$('.unit-article').on('click', '.meta .author', function(event) {
    sendGaEvent('Post', 'Show Author', event.currentTarget);
});
$('.unit-article').on('click', '.meta .license-icon', function(event) {
    sendGaEvent('Post', 'Show License', event.currentTarget);
});
$('.unit-article').on('click', '.meta .list-tag a', function(event) {
    sendGaEvent('Post', 'Click Tag', event.currentTarget);
});
$('.unit-article').on('click', '.meta .list-category', function(event) {
    sendGaEvent('Post', 'Click Category', event.currentTarget);
});
$('.unit-foot').delegate('.addthis_toolbox .btn-share-post', 'click', function(event) {
    sendGaEvent('Post', 'Share Post', event.currentTarget);
});
$('.search-wrapper').on('click', '.results a', function(event) {
    sendGaEvent('Search', 'Click Search Result', event.currentTarget);
});
$('.search-wrapper').on('click', '.btn-close', function(event) {
    sendGaEvent('Search', 'Close Search', event.currentTarget);
});
</script>



<script src='//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js'></script>
<script src='//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-buttons.min.js'></script>
<script src="/assets/javascripts/unveil/jquery.unveil.min.js"></script>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script>
    window.jQuery.fancybox || document.write('<script src="/assets/javascripts/fancybox/jquery.fancybox.pack.js?v=2.1.4"><\/script>')
    window.jQuery.fancybox.helpers.buttons || document.write('<script src="/assets/javascripts/fancybox/helpers/jquery.fancybox-buttons.js?v=1.0.5"><\/script>')
</script>

<script>
    $("head").append('<link rel="stylesheet" href="/assets/javascripts/fancybox/jquery.fancybox.css?v=2.1.4" type="text/css" />');
    $("head").append('<link rel="stylesheet" href="/assets/javascripts/fancybox/helpers/jquery.fancybox-buttons.css?v=1.0.5" type="text/css" />');
    $(".post-image").fancybox({
        prevEffect: 'none',
        nextEffect: 'none',
        closeBtn: true,
        helpers: {
            title: {
                type: 'float'
            }
        }
    });
    $(document).ready(function () {
        $(".post-image > img").unveil(450);
    });
</script>

</body>

</html>